{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)\n",
      "  (0, 3278)\t1\n",
      "  (0, 7728)\t1\n",
      "  (0, 615)\t1\n",
      "  (0, 11296)\t1\n",
      "  (0, 11036)\t1\n",
      "  (0, 10709)\t1\n",
      "  (0, 5115)\t1\n",
      "  (0, 8376)\t1\n",
      "  (0, 6639)\t1\n",
      "  (0, 1044)\t1\n",
      "  (0, 10988)\t1\n",
      "  (0, 9676)\t1\n",
      "  (1, 751)\t1\n",
      "  (1, 1964)\t1\n",
      "  (1, 4910)\t1\n",
      "  (1, 8554)\t1\n",
      "  (1, 5687)\t1\n",
      "  (1, 1532)\t1\n",
      "  (1, 11110)\t1\n",
      "  (1, 10980)\t1\n",
      "  (1, 7674)\t1\n",
      "  (1, 11138)\t1\n",
      "  (1, 4860)\t1\n",
      "  (1, 7418)\t1\n",
      "  (1, 10426)\t2\n",
      "  :\t:\n",
      "  (10239, 6853)\t1\n",
      "  (10239, 10594)\t1\n",
      "  (10239, 3989)\t1\n",
      "  (10239, 10918)\t1\n",
      "  (10239, 8996)\t1\n",
      "  (10239, 10660)\t1\n",
      "  (10239, 2549)\t1\n",
      "  (10239, 11622)\t1\n",
      "  (10239, 2568)\t1\n",
      "  (10239, 799)\t1\n",
      "  (10239, 11660)\t2\n",
      "  (10239, 12158)\t1\n",
      "  (10239, 3309)\t1\n",
      "  (10239, 11004)\t1\n",
      "  (10239, 11013)\t1\n",
      "  (10239, 6603)\t1\n",
      "  (10239, 6327)\t1\n",
      "  (10239, 12151)\t2\n",
      "  (10239, 1159)\t1\n",
      "  (10239, 7824)\t1\n",
      "  (10239, 7828)\t1\n",
      "  (10239, 5267)\t1\n",
      "  (10239, 11110)\t2\n",
      "  (10239, 7672)\t2\n",
      "  (10239, 10988)\t1\n",
      "0        Says the Annies List political group supports ...\n",
      "1        When did the decline of coal start? It started...\n",
      "2        Hillary Clinton agrees with John McCain \"by vo...\n",
      "3        Health care reform legislation is likely to ma...\n",
      "4        The economic turnaround started at the end of ...\n",
      "5        The Chicago Bears have had more starting quart...\n",
      "6        Jim Dunnam has not lived in the district he re...\n",
      "7        I'm the only person on this stage who has work...\n",
      "8        However, it took $19.5 million in Oregon Lotte...\n",
      "9        Says GOP primary opponents Glenn Grothman and ...\n",
      "10       For the first time in history, the share of th...\n",
      "11       Since 2000, nearly 12 million Americans have s...\n",
      "12       When Mitt Romney was governor of Massachusetts...\n",
      "13       The economy bled $24 billion due to the govern...\n",
      "14       Most of the (Affordable Care Act) has already ...\n",
      "15       In this last election in November, ... 63 perc...\n",
      "16       McCain opposed a requirement that the governme...\n",
      "17       U.S. Rep. Ron Kind, D-Wis., and his fellow Dem...\n",
      "18       Water rates in Manila, Philippines, were raise...\n",
      "19       Almost 100,000 people left Puerto Rico last year.\n",
      "20       Women and men both are making less when you ad...\n",
      "21       The United States has the highest corporate ta...\n",
      "22       We just had the best year for the auto industr...\n",
      "23       Says Scott Walker favors cutting up to 350,000...\n",
      "24       Says Mitt Romney wants to get rid of Planned P...\n",
      "25                   I dont know who (Jonathan Gruber) is.\n",
      "26       Hate crimes against American Muslims and mosqu...\n",
      "27       Rick Perry has never lost an election and rema...\n",
      "28       ISIS supporter tweeted at 10:34 a.m. Shooting ...\n",
      "29       Youth unemployment in minority communities is ...\n",
      "                               ...                        \n",
      "10210    Since the Affordable Care Act passed, 90 perce...\n",
      "10211    Debt has almost doubled in Austin under Gov. P...\n",
      "10212    Lets say (Republicans) take away half of our d...\n",
      "10213    Theres a tremendous other number of public off...\n",
      "10214    Under last years health care reform, a bunch o...\n",
      "10215    The Obama administration spent $205,075 in sti...\n",
      "10216    There has been no net global warming for over ...\n",
      "10217    Thanks to the Obama administrations negotiatio...\n",
      "10218    This race will be the Democrats top target thi...\n",
      "10219    Georgia Public Service Commission member Stan ...\n",
      "10220    Says he and Mitt Romney agreed on tying minimu...\n",
      "10221    As a result of Obamacare, California seniors f...\n",
      "10222    For the first time since the Korean War, total...\n",
      "10223    Says Rick Perry turned down our invitation to ...\n",
      "10224    In 2012, the state put together a list of over...\n",
      "10225    The Republican Party lost 1.1 million register...\n",
      "10226    The proudest accomplishment (of my tenure) was...\n",
      "10227    Recently though, the media has reported on tho...\n",
      "10228    Stopped by Smiley Cookie to pick up some great...\n",
      "10229     Mike Trainor...still owes $250,000 to the state.\n",
      "10230    The Supreme Courts views are radically out of ...\n",
      "10231    When it comes to the state deficit, Wisconsin ...\n",
      "10232    Eighty percent of the net new jobs created in ...\n",
      "10233    Mayor Fung wants to punish our childrens educa...\n",
      "10234    Under the ruling of the Supreme Court, any lob...\n",
      "10235    There are a larger number of shark attacks in ...\n",
      "10236    Democrats have now become the party of the [At...\n",
      "10237    Says an alternative to Social Security that op...\n",
      "10238    On lifting the U.S. Cuban embargo and allowing...\n",
      "10239    The Department of Veterans Affairs has a manua...\n",
      "Name: Statement, Length: 10240, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import DataPrep\n",
    "import FeatureSelection\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import  LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#string to test\n",
    "doc_new = ['obama is running for president in 2019']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The feature selection has been done in FeatureSelection.py\n",
    "# Here we will create models using those features for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Building classifier using naive bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6072128577028616"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_pipeline = Pipeline([\n",
    "        ('NBCV',FeatureSelection.countV),\n",
    "        ('nb_clf',MultinomialNB())])\n",
    "nb_pipeline.fit(DataPrep.train_news['Statement'],DataPrep.train_news['Label'])\n",
    "predicted_nb = nb_pipeline.predict(DataPrep.test_news['Statement'])\n",
    "np.mean(predicted_nb == DataPrep.test_news['Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Building classifier using logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5985887887103096"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logR_pipeline = Pipeline([\n",
    "        ('LogRCV',FeatureSelection.countV),\n",
    "        ('LogR_clf',LogisticRegression(solver='lbfgs',max_iter=10000))\n",
    "        ])\n",
    "\n",
    "logR_pipeline.fit(DataPrep.train_news['Statement'],DataPrep.train_news['Label'])\n",
    "predicted_LogR = logR_pipeline.predict(DataPrep.test_news['Statement'])\n",
    "np.mean(predicted_LogR == DataPrep.test_news['Label'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building classifier using Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harikesh\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5723245785966288"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_pipeline = Pipeline([\n",
    "        ('svmCV',FeatureSelection.countV),\n",
    "        ('svm_clf',svm.LinearSVC(max_iter=1000))\n",
    "        ])\n",
    "\n",
    "svm_pipeline.fit(DataPrep.train_news['Statement'],DataPrep.train_news['Label'])\n",
    "predicted_svm = svm_pipeline.predict(DataPrep.test_news['Statement'])\n",
    "np.mean(predicted_svm == DataPrep.test_news['Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building classifier using SVM Stochastic Gradient Descent on hinge loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6017248137985104"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_pipeline = Pipeline([\n",
    "       ('svm2CV',FeatureSelection.countV),\n",
    "       ('svm2_clf',SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, max_iter=10,tol=0.21))\n",
    "       ])\n",
    "\n",
    "sgd_pipeline.fit(DataPrep.train_news['Statement'],DataPrep.train_news['Label'])\n",
    "predicted_sgd = sgd_pipeline.predict(DataPrep.test_news['Statement'])\n",
    "np.mean(predicted_sgd == DataPrep.test_news['Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building classifier using random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6181889455115641"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest = Pipeline([\n",
    "       ('rfCV',FeatureSelection.countV),\n",
    "       ('rf_clf',RandomForestClassifier(n_estimators=200,n_jobs=3))\n",
    "       ])\n",
    "   \n",
    "random_forest.fit(DataPrep.train_news['Statement'],DataPrep.train_news['Label'])\n",
    "predicted_rf = random_forest.predict(DataPrep.test_news['Statement'])\n",
    "np.mean(predicted_rf == DataPrep.test_news['Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User defined functon for K-Fold cross validatoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_confusion_matrix(classifier):\n",
    "    \n",
    "    k_fold = KFold(n_splits=2)\n",
    "    scores = []\n",
    "    confusion = np.array([[0,0],[0,0]])\n",
    "    X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "    \n",
    "    for train_ind, test_ind in k_fold.split(X):\n",
    "        train_text = DataPrep.train_news.iloc[train_ind]['Statement'] \n",
    "        train_y = DataPrep.train_news.iloc[train_ind]['Label']\n",
    "    \n",
    "        test_text = DataPrep.train_news.iloc[test_ind]['Statement']\n",
    "        test_y = DataPrep.train_news.iloc[test_ind]['Label']\n",
    "        \n",
    "        classifier.fit(train_text,train_y)\n",
    "        predictions = classifier.predict(test_text)\n",
    "        \n",
    "        confusion += confusion_matrix(test_y,predictions)\n",
    "        score = f1_score(test_y,predictions)\n",
    "        scores.append(score)\n",
    "    \n",
    "    return (print('Total statements classified:', len(DataPrep.train_news)),\n",
    "    print('Score:', sum(scores)/len(scores)),\n",
    "    print('score length', len(scores)),\n",
    "    print('Confusion matrix:'),\n",
    "    print(confusion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-fold cross validation for all classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total statements classified: 10240\n",
      "Score: 0.6666666666666666\n",
      "score length 2\n",
      "Confusion matrix:\n",
      "[[0 2]\n",
      " [0 2]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None, None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_confusion_matrix(nb_pipeline)\n",
    "# build_confusion_matrix(logR_pipeline)\n",
    "# build_confusion_matrix(svm_pipeline)\n",
    "# build_confusion_matrix(sgd_pipeline)\n",
    "# build_confusion_matrix(random_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building classifier using naive-bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5938847510780086"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_pipeline_ngram = Pipeline([\n",
    "        ('nb_tfidf',FeatureSelection.tfidf_ngram),\n",
    "        ('nb_clf',MultinomialNB())])\n",
    "\n",
    "nb_pipeline_ngram.fit(DataPrep.train_news['Statement'],DataPrep.train_news['Label'])\n",
    "predicted_nb_ngram = nb_pipeline_ngram.predict(DataPrep.test_news['Statement'])\n",
    "np.mean(predicted_nb_ngram == DataPrep.test_news['Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building classifier using logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6193649549196394"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logR_pipeline_ngram = Pipeline([\n",
    "        ('LogR_tfidf',FeatureSelection.tfidf_ngram),\n",
    "        ('LogR_clf',LogisticRegression(penalty=\"l2\",C=1,solver='lbfgs'))\n",
    "        ])\n",
    "\n",
    "logR_pipeline_ngram.fit(DataPrep.train_news['Statement'],DataPrep.train_news['Label'])\n",
    "predicted_LogR_ngram = logR_pipeline_ngram.predict(DataPrep.test_news['Statement'])\n",
    "np.mean(predicted_LogR_ngram == DataPrep.test_news['Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building classifier using Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6170129361034888"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_pipeline_ngram = Pipeline([\n",
    "        ('svm_tfidf',FeatureSelection.tfidf_ngram),\n",
    "        ('svm_clf',svm.LinearSVC())\n",
    "        ])\n",
    "\n",
    "svm_pipeline_ngram.fit(DataPrep.train_news['Statement'],DataPrep.train_news['Label'])\n",
    "predicted_svm_ngram = svm_pipeline_ngram.predict(DataPrep.test_news['Statement'])\n",
    "np.mean(predicted_svm_ngram == DataPrep.test_news['Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building classifier using Stochastic Gradient Descent (SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5417483339866719"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_pipeline_ngram = Pipeline([\n",
    "        ('sgd_tfidf',FeatureSelection.tfidf_ngram),\n",
    "        ('sgd_clf',SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, max_iter=50,tol=0.21))\n",
    "        ])\n",
    "\n",
    "sgd_pipeline_ngram.fit(DataPrep.train_news['Statement'],DataPrep.train_news['Label'])\n",
    "predicted_sgd_ngram = sgd_pipeline_ngram.predict(DataPrep.test_news['Statement'])\n",
    "np.mean(predicted_sgd_ngram == DataPrep.test_news['Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building classifier using random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6032928263426107"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_ngram = Pipeline([\n",
    "       ('rf_tfidf',FeatureSelection.tfidf_ngram),\n",
    "       ('rf_clf',RandomForestClassifier(n_estimators=300,n_jobs=3))\n",
    "       ])\n",
    "   \n",
    "random_forest_ngram.fit(DataPrep.train_news['Statement'],DataPrep.train_news['Label'])\n",
    "predicted_rf_ngram = random_forest_ngram.predict(DataPrep.test_news['Statement'])\n",
    "np.mean(predicted_rf_ngram == DataPrep.test_news['Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-fold cross validation for all classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total statements classified: 10240\n",
      "Score: 1.0\n",
      "score length 2\n",
      "Confusion matrix:\n",
      "[[2 0]\n",
      " [0 2]]\n",
      "Total statements classified: 10240\n",
      "Score: 0.6666666666666666\n",
      "score length 2\n",
      "Confusion matrix:\n",
      "[[0 2]\n",
      " [0 2]]\n",
      "Total statements classified: 10240\n",
      "Score: 0.6666666666666666\n",
      "score length 2\n",
      "Confusion matrix:\n",
      "[[0 2]\n",
      " [0 2]]\n",
      "Total statements classified: 10240\n",
      "Score: 0.8333333333333333\n",
      "score length 2\n",
      "Confusion matrix:\n",
      "[[1 1]\n",
      " [0 2]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None, None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_confusion_matrix(nb_pipeline_ngram)\n",
    "build_confusion_matrix(logR_pipeline_ngram)\n",
    "build_confusion_matrix(svm_pipeline_ngram)\n",
    "build_confusion_matrix(sgd_pipeline_ngram)\n",
    "# build_confusion_matrix(random_forest_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.72      0.19      0.30      1169\n",
      "        True       0.58      0.94      0.71      1382\n",
      "\n",
      "   micro avg       0.59      0.59      0.59      2551\n",
      "   macro avg       0.65      0.56      0.51      2551\n",
      "weighted avg       0.64      0.59      0.52      2551\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.64      0.39      0.49      1169\n",
      "        True       0.61      0.81      0.70      1382\n",
      "\n",
      "   micro avg       0.62      0.62      0.62      2551\n",
      "   macro avg       0.62      0.60      0.59      2551\n",
      "weighted avg       0.62      0.62      0.60      2551\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.61      0.47      0.53      1169\n",
      "        True       0.62      0.74      0.68      1382\n",
      "\n",
      "   micro avg       0.62      0.62      0.62      2551\n",
      "   macro avg       0.61      0.61      0.60      2551\n",
      "weighted avg       0.62      0.62      0.61      2551\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.00      0.00      0.00      1169\n",
      "        True       0.54      1.00      0.70      1382\n",
      "\n",
      "   micro avg       0.54      0.54      0.54      2551\n",
      "   macro avg       0.27      0.50      0.35      2551\n",
      "weighted avg       0.29      0.54      0.38      2551\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harikesh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Harikesh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Harikesh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2551,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(DataPrep.test_news['Label'], predicted_nb_ngram))\n",
    "print(classification_report(DataPrep.test_news['Label'], predicted_LogR_ngram))\n",
    "print(classification_report(DataPrep.test_news['Label'], predicted_svm_ngram))\n",
    "print(classification_report(DataPrep.test_news['Label'], predicted_sgd_ngram))\n",
    "# print(classification_report(DataPrep.test_news['Label'], predicted_rf_ngram))\n",
    "\n",
    "DataPrep.test_news['Label'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 0.8650876 ,  0.67499595,  0.69953132,  0.59600739,  3.12105222,\n",
       "         3.55489535,  3.27663689,  3.49006381,  5.84066887,  7.2863111 ,\n",
       "         5.31857505,  7.23924003,  6.37415037,  8.27546363,  6.30932126,\n",
       "         8.29860234,  7.87693057, 12.03720527,  9.21316333, 10.38375692]),\n",
       " 'std_fit_time': array([0.07882487, 0.04629213, 0.01033778, 0.04918175, 0.16313624,\n",
       "        0.20447634, 0.67681713, 0.3290763 , 1.13925427, 0.39362705,\n",
       "        0.44238914, 0.25675977, 0.6452461 , 0.9551358 , 0.70247206,\n",
       "        0.75238208, 0.86478133, 0.71376853, 1.0666267 , 0.56558964]),\n",
       " 'mean_score_time': array([0.07699223, 0.08038406, 0.07878747, 0.07699299, 0.17433319,\n",
       "        0.19448056, 0.19827104, 0.14521484, 0.23038535, 0.23417315,\n",
       "        0.28703318, 0.25032754, 0.23238196, 0.2569222 , 0.22220864,\n",
       "        0.25851254, 0.28922815, 0.34807081, 0.35644188, 0.29814367]),\n",
       " 'std_score_time': array([0.00247766, 0.00850137, 0.0061815 , 0.00765901, 0.03187903,\n",
       "        0.05377705, 0.03112971, 0.03307109, 0.04022198, 0.06634045,\n",
       "        0.07430681, 0.05145495, 0.03423894, 0.02072012, 0.02800669,\n",
       "        0.06036033, 0.0781229 , 0.04820557, 0.0887458 , 0.0935122 ]),\n",
       " 'param_LogR_tfidf__ngram_range': masked_array(data=[(1, 1), (1, 1), (1, 1), (1, 1), (1, 2), (1, 2), (1, 2),\n",
       "                    (1, 2), (1, 3), (1, 3), (1, 3), (1, 3), (1, 4), (1, 4),\n",
       "                    (1, 4), (1, 4), (1, 5), (1, 5), (1, 5), (1, 5)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_LogR_tfidf__smooth_idf': masked_array(data=[True, True, False, False, True, True, False, False,\n",
       "                    True, True, False, False, True, True, False, False,\n",
       "                    True, True, False, False],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_LogR_tfidf__use_idf': masked_array(data=[True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'LogR_tfidf__ngram_range': (1, 1),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 1),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': False},\n",
       "  {'LogR_tfidf__ngram_range': (1, 1),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 1),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': False},\n",
       "  {'LogR_tfidf__ngram_range': (1, 2),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 2),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': False},\n",
       "  {'LogR_tfidf__ngram_range': (1, 2),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 2),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': False},\n",
       "  {'LogR_tfidf__ngram_range': (1, 3),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 3),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': False},\n",
       "  {'LogR_tfidf__ngram_range': (1, 3),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 3),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': False},\n",
       "  {'LogR_tfidf__ngram_range': (1, 4),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 4),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': False},\n",
       "  {'LogR_tfidf__ngram_range': (1, 4),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 4),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': False},\n",
       "  {'LogR_tfidf__ngram_range': (1, 5),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 5),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': False},\n",
       "  {'LogR_tfidf__ngram_range': (1, 5),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 5),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': False}],\n",
       " 'split0_test_score': array([0.61369315, 0.6181909 , 0.61269365, 0.6181909 , 0.62018991,\n",
       "        0.6181909 , 0.61769115, 0.6181909 , 0.62068966, 0.6181909 ,\n",
       "        0.62168916, 0.6181909 , 0.61669165, 0.61569215, 0.61769115,\n",
       "        0.61569215, 0.6141929 , 0.6141929 , 0.61069465, 0.6141929 ]),\n",
       " 'split1_test_score': array([0.617 , 0.62  , 0.6175, 0.62  , 0.625 , 0.622 , 0.624 , 0.622 ,\n",
       "        0.624 , 0.616 , 0.624 , 0.616 , 0.623 , 0.6135, 0.62  , 0.6135,\n",
       "        0.621 , 0.613 , 0.6185, 0.613 ]),\n",
       " 'split2_test_score': array([0.5955, 0.6025, 0.5975, 0.6025, 0.603 , 0.6035, 0.606 , 0.6035,\n",
       "        0.605 , 0.605 , 0.6085, 0.605 , 0.608 , 0.604 , 0.607 , 0.604 ,\n",
       "        0.6075, 0.603 , 0.6095, 0.603 ]),\n",
       " 'split3_test_score': array([0.6   , 0.608 , 0.601 , 0.608 , 0.6095, 0.6055, 0.609 , 0.6055,\n",
       "        0.6115, 0.607 , 0.6145, 0.607 , 0.616 , 0.611 , 0.6165, 0.611 ,\n",
       "        0.62  , 0.611 , 0.618 , 0.611 ]),\n",
       " 'split4_test_score': array([0.5977989 , 0.60430215, 0.60030015, 0.60430215, 0.6138069 ,\n",
       "        0.60630315, 0.6118059 , 0.60630315, 0.61230615, 0.60730365,\n",
       "        0.61430715, 0.60730365, 0.6158079 , 0.6058029 , 0.61830915,\n",
       "        0.6058029 , 0.61630815, 0.60530265, 0.61730865, 0.60530265]),\n",
       " 'mean_test_score': array([0.6048, 0.6106, 0.6058, 0.6106, 0.6143, 0.6111, 0.6137, 0.6111,\n",
       "        0.6147, 0.6107, 0.6166, 0.6107, 0.6159, 0.61  , 0.6159, 0.61  ,\n",
       "        0.6158, 0.6093, 0.6148, 0.6093]),\n",
       " 'std_test_score': array([0.00879191, 0.00718364, 0.0078307 , 0.00718364, 0.00774818,\n",
       "        0.00749979, 0.00643418, 0.00749979, 0.00681823, 0.00532806,\n",
       "        0.00558475, 0.00532806, 0.00476373, 0.00445586, 0.0045911 ,\n",
       "        0.00445586, 0.00482519, 0.00438619, 0.00387743, 0.00438619]),\n",
       " 'rank_test_score': array([20, 13, 19, 13,  7,  9,  8,  9,  6, 11,  1, 11,  2, 15,  2, 15,  4,\n",
       "        17,  5, 17]),\n",
       " 'split0_train_score': array([0.80760095, 0.76859607, 0.81172647, 0.76859607, 0.9016127 ,\n",
       "        0.84660583, 0.90773847, 0.84660583, 0.93099137, 0.87735967,\n",
       "        0.93586698, 0.87735967, 0.94461808, 0.89586198, 0.9496187 ,\n",
       "        0.89586198, 0.95461933, 0.90411301, 0.95974497, 0.90411301]),\n",
       " 'split1_train_score': array([0.800125, 0.76025 , 0.805375, 0.76025 , 0.891875, 0.840375,\n",
       "        0.89775 , 0.840375, 0.924125, 0.8715  , 0.931375, 0.8715  ,\n",
       "        0.943875, 0.886375, 0.948875, 0.886375, 0.952125, 0.896375,\n",
       "        0.95825 , 0.896375]),\n",
       " 'split2_train_score': array([0.801625, 0.764875, 0.80525 , 0.764875, 0.89225 , 0.841125,\n",
       "        0.898125, 0.841125, 0.923125, 0.874   , 0.929125, 0.874   ,\n",
       "        0.939625, 0.887875, 0.945625, 0.887875, 0.949875, 0.897875,\n",
       "        0.954375, 0.897875]),\n",
       " 'split3_train_score': array([0.803125, 0.7635  , 0.806125, 0.7635  , 0.8965  , 0.839875,\n",
       "        0.902375, 0.839875, 0.927375, 0.872125, 0.933125, 0.872125,\n",
       "        0.943875, 0.887625, 0.9495  , 0.887625, 0.953875, 0.89675 ,\n",
       "        0.958875, 0.89675 ]),\n",
       " 'split4_train_score': array([0.80564929, 0.768029  , 0.80839895, 0.768029  , 0.90051244,\n",
       "        0.84164479, 0.90538683, 0.84164479, 0.93000875, 0.87814023,\n",
       "        0.93500812, 0.87814023, 0.94313211, 0.89401325, 0.94938133,\n",
       "        0.89401325, 0.9536308 , 0.90176228, 0.95925509, 0.90176228]),\n",
       " 'mean_train_score': array([0.80362505, 0.76505001, 0.80737508, 0.76505001, 0.89655003,\n",
       "        0.84192512, 0.90227506, 0.84192512, 0.92712502, 0.87462498,\n",
       "        0.93290002, 0.87462498, 0.94302504, 0.89035005, 0.94860001,\n",
       "        0.89035005, 0.95282502, 0.89937506, 0.95810001, 0.89937506]),\n",
       " 'std_train_score': array([0.00269837, 0.0030634 , 0.00245201, 0.0030634 , 0.00404178,\n",
       "        0.002418  , 0.00393042, 0.002418  , 0.00310893, 0.00269227,\n",
       "        0.00244434, 0.00269227, 0.00176377, 0.003825  , 0.00150894,\n",
       "        0.003825  , 0.00168309, 0.00304265, 0.00192556, 0.00304265])}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'LogR_tfidf__ngram_range': [(1, 1), (1, 2),(1,3),(1,4),(1,5)],\n",
    "               'LogR_tfidf__use_idf': (True, False),\n",
    "               'LogR_tfidf__smooth_idf': (True, False)\n",
    "}\n",
    "\n",
    "gs_clf = GridSearchCV(logR_pipeline_ngram, parameters, n_jobs=-1, cv=5, return_train_score=True)\n",
    "gs_clf = gs_clf.fit(DataPrep.train_news['Statement'][:10000],DataPrep.train_news['Label'][:10000])\n",
    "\n",
    "gs_clf.best_score_\n",
    "gs_clf.best_params_\n",
    "gs_clf.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.50365229, 0.48031149, 0.44999471, 0.35823636, 1.19340777,\n",
       "        1.34619818, 1.36036024, 1.25584044, 1.82611661, 1.61128964,\n",
       "        1.64559827, 1.47206178, 2.78335576, 2.20310693, 2.3217886 ,\n",
       "        2.18236284, 2.72291856, 2.55456781, 2.89864969, 2.8816916 ,\n",
       "        0.45697742, 0.52958364, 0.54614024, 0.54773469, 1.53528829,\n",
       "        1.11182671, 1.04321256, 1.09646163, 1.68289685, 1.66015902,\n",
       "        1.72717886, 1.63901772, 2.95741282, 3.38594151, 2.99102807,\n",
       "        3.75336609, 3.12424498, 3.2020359 , 3.23355012, 3.35981035]),\n",
       " 'std_fit_time': array([0.03916896, 0.02571261, 0.03036592, 0.01050268, 0.09102592,\n",
       "        0.07420291, 0.03797547, 0.02387304, 0.0313483 , 0.05291226,\n",
       "        0.03202082, 0.04350512, 0.182293  , 0.0748277 , 0.12454967,\n",
       "        0.15798376, 0.11796597, 0.11514162, 0.13473082, 0.1958148 ,\n",
       "        0.01490453, 0.11777455, 0.10909393, 0.12806502, 0.2852079 ,\n",
       "        0.14848046, 0.10094447, 0.13755933, 0.1024291 , 0.09234277,\n",
       "        0.11057269, 0.09448794, 0.89739819, 0.71165257, 0.46885398,\n",
       "        0.30621963, 0.21612083, 0.22053962, 0.36056605, 0.22121808]),\n",
       " 'mean_score_time': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.08197985, 0.08118601, 0.12366962, 0.08178267, 0.16875176,\n",
       "        0.12207355, 0.12626128, 0.11888294, 0.16097088, 0.15019932,\n",
       "        0.15019817, 0.14720359, 0.23907142, 0.23687148, 0.27925472,\n",
       "        0.22839112, 0.22599773, 0.27386856, 0.28803339, 0.19168963]),\n",
       " 'std_score_time': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00750096, 0.00470215, 0.01707679, 0.00441586, 0.01990909,\n",
       "        0.00712419, 0.00573232, 0.0037535 , 0.0102403 , 0.00514799,\n",
       "        0.00728915, 0.00994119, 0.04173255, 0.04078988, 0.07202008,\n",
       "        0.03469255, 0.01543625, 0.04997253, 0.05000191, 0.04183368]),\n",
       " 'param_svm_clf__penalty': masked_array(data=['l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1',\n",
       "                    'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1',\n",
       "                    'l1', 'l1', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_svm_tfidf__ngram_range': masked_array(data=[(1, 1), (1, 1), (1, 1), (1, 1), (1, 2), (1, 2), (1, 2),\n",
       "                    (1, 2), (1, 3), (1, 3), (1, 3), (1, 3), (1, 4), (1, 4),\n",
       "                    (1, 4), (1, 4), (1, 5), (1, 5), (1, 5), (1, 5), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 2), (1, 2), (1, 2), (1, 2),\n",
       "                    (1, 3), (1, 3), (1, 3), (1, 3), (1, 4), (1, 4), (1, 4),\n",
       "                    (1, 4), (1, 5), (1, 5), (1, 5), (1, 5)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_svm_tfidf__smooth_idf': masked_array(data=[True, True, False, False, True, True, False, False,\n",
       "                    True, True, False, False, True, True, False, False,\n",
       "                    True, True, False, False, True, True, False, False,\n",
       "                    True, True, False, False, True, True, False, False,\n",
       "                    True, True, False, False, True, True, False, False],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_svm_tfidf__use_idf': masked_array(data=[True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 1),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 1),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 1),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 1),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 2),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 2),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 2),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 2),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 3),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 3),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 3),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 3),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 4),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 4),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 4),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 4),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 5),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 5),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 5),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 5),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 1),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 1),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 1),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 1),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 2),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 2),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 2),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 2),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 3),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 3),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 3),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 3),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 4),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 4),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 4),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 4),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 5),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 5),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 5),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 5),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': False}],\n",
       " 'split0_test_score': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.58970515, 0.59970015, 0.59170415, 0.59970015, 0.60769615,\n",
       "        0.60669665, 0.61069465, 0.60669665, 0.61169415, 0.60769615,\n",
       "        0.61369315, 0.60769615, 0.6141929 , 0.6151924 , 0.6131934 ,\n",
       "        0.6151924 , 0.6171914 , 0.6151924 , 0.6161919 , 0.6151924 ]),\n",
       " 'split1_test_score': array([0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    ,\n",
       "        0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    ,\n",
       "        0.    , 0.    , 0.    , 0.    , 0.593 , 0.602 , 0.592 , 0.602 ,\n",
       "        0.6235, 0.621 , 0.625 , 0.621 , 0.6235, 0.6175, 0.625 , 0.6175,\n",
       "        0.621 , 0.622 , 0.621 , 0.622 , 0.621 , 0.621 , 0.622 , 0.621 ]),\n",
       " 'split2_test_score': array([0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    ,\n",
       "        0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    ,\n",
       "        0.    , 0.    , 0.    , 0.    , 0.572 , 0.58  , 0.5735, 0.58  ,\n",
       "        0.587 , 0.588 , 0.589 , 0.588 , 0.5915, 0.59  , 0.5905, 0.59  ,\n",
       "        0.5895, 0.5915, 0.59  , 0.5915, 0.591 , 0.5935, 0.5925, 0.5935]),\n",
       " 'split3_test_score': array([0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    ,\n",
       "        0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    ,\n",
       "        0.    , 0.    , 0.    , 0.    , 0.5715, 0.583 , 0.574 , 0.583 ,\n",
       "        0.5855, 0.5835, 0.586 , 0.5835, 0.5915, 0.5945, 0.592 , 0.5945,\n",
       "        0.5975, 0.598 , 0.598 , 0.598 , 0.6   , 0.597 , 0.597 , 0.597 ]),\n",
       " 'split4_test_score': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.58129065, 0.5867934 , 0.58229115, 0.5867934 , 0.5957979 ,\n",
       "        0.5937969 , 0.59729865, 0.5937969 , 0.60830415, 0.60330165,\n",
       "        0.6108054 , 0.60330165, 0.61030515, 0.60630315, 0.6128064 ,\n",
       "        0.60630315, 0.61230615, 0.6048024 , 0.6138069 , 0.6048024 ]),\n",
       " 'mean_test_score': array([0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    ,\n",
       "        0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    ,\n",
       "        0.    , 0.    , 0.    , 0.    , 0.5815, 0.5903, 0.5827, 0.5903,\n",
       "        0.5999, 0.5986, 0.6016, 0.5986, 0.6053, 0.6026, 0.6064, 0.6026,\n",
       "        0.6065, 0.6066, 0.607 , 0.6066, 0.6083, 0.6063, 0.6083, 0.6063]),\n",
       " 'std_test_score': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00883065, 0.0089103 , 0.00810065, 0.0089103 , 0.01420112,\n",
       "        0.01364388, 0.01449777, 0.01364388, 0.01234541, 0.00972477,\n",
       "        0.01325703, 0.00972477, 0.01143619, 0.01107325, 0.01129668,\n",
       "        0.01107325, 0.01117683, 0.01046686, 0.0114686 , 0.01046686]),\n",
       " 'rank_test_score': array([21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "        21, 21, 21, 20, 17, 19, 17, 14, 15, 13, 15, 10, 11,  7, 11,  6,  4,\n",
       "         3,  4,  1,  8,  1,  8]),\n",
       " 'split0_train_score': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.92411551, 0.89236155, 0.92661583, 0.89236155, 0.99912489,\n",
       "        0.99637455, 0.99924991, 0.99637455, 0.99962495, 0.99912489,\n",
       "        0.99962495, 0.99912489, 0.99962495, 0.99937492, 0.99962495,\n",
       "        0.99937492, 0.99962495, 0.99949994, 0.99962495, 0.99949994]),\n",
       " 'split1_train_score': array([0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "        0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "        0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "        0.      , 0.      , 0.920375, 0.88775 , 0.923625, 0.88775 ,\n",
       "        0.999   , 0.995375, 0.999125, 0.995375, 0.999375, 0.99875 ,\n",
       "        0.999375, 0.99875 , 0.999375, 0.999125, 0.999375, 0.999125,\n",
       "        0.999375, 0.999125, 0.999375, 0.999125]),\n",
       " 'split2_train_score': array([0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "        0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "        0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "        0.      , 0.      , 0.920375, 0.890875, 0.9235  , 0.890875,\n",
       "        0.999125, 0.99625 , 0.99925 , 0.99625 , 0.9995  , 0.999125,\n",
       "        0.9995  , 0.999125, 0.9995  , 0.999375, 0.9995  , 0.999375,\n",
       "        0.9995  , 0.999375, 0.9995  , 0.999375]),\n",
       " 'split3_train_score': array([0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "        0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "        0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "        0.      , 0.      , 0.9245  , 0.89275 , 0.928375, 0.89275 ,\n",
       "        0.999375, 0.99575 , 0.999375, 0.99575 , 0.9995  , 0.99925 ,\n",
       "        0.9995  , 0.99925 , 0.9995  , 0.999375, 0.9995  , 0.999375,\n",
       "        0.9995  , 0.999375, 0.9995  , 0.999375]),\n",
       " 'split4_train_score': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.92438445, 0.89138858, 0.92713411, 0.89138858, 0.99950006,\n",
       "        0.99562555, 0.99950006, 0.99562555, 0.99950006, 0.99925009,\n",
       "        0.99950006, 0.99925009, 0.99950006, 0.99950006, 0.99950006,\n",
       "        0.99950006, 0.99950006, 0.99950006, 0.99950006, 0.99950006]),\n",
       " 'mean_train_score': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.92274999, 0.89102502, 0.92584999, 0.89102502, 0.99922499,\n",
       "        0.99587502, 0.99929999, 0.99587502, 0.9995    , 0.9991    ,\n",
       "        0.9995    , 0.9991    , 0.9995    , 0.99935   , 0.9995    ,\n",
       "        0.99935   , 0.9995    , 0.999375  , 0.9995    , 0.999375  ]),\n",
       " 'std_train_score': array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.94318362e-03, 1.76874480e-03, 1.95367218e-03, 1.76874480e-03,\n",
       "        1.83742354e-04, 3.78952218e-04, 1.27502459e-04, 3.78952218e-04,\n",
       "        7.90421227e-05, 1.83724072e-04, 7.90421227e-05, 1.83724072e-04,\n",
       "        7.90421227e-05, 1.22486612e-04, 7.90421227e-05, 1.22486612e-04,\n",
       "        7.90421227e-05, 1.36930642e-04, 7.90421227e-05, 1.36930642e-04])}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'svm_tfidf__ngram_range': [(1, 1), (1, 2),(1,3),(1,4),(1,5)],\n",
    "               'svm_tfidf__use_idf': (True, False),\n",
    "               'svm_tfidf__smooth_idf': (True, False),\n",
    "               'svm_clf__penalty': ('l1','l2'),\n",
    "}\n",
    "\n",
    "gs_clf = GridSearchCV(svm_pipeline_ngram, parameters, n_jobs=-1, cv=5, return_train_score=True,error_score=0.0)\n",
    "gs_clf = gs_clf.fit(DataPrep.train_news['Statement'][:10000],DataPrep.train_news['Label'][:10000])\n",
    "\n",
    "gs_clf.best_score_\n",
    "gs_clf.best_params_\n",
    "gs_clf.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running both random forest and logistic regression models again with best parameter found with GridSearch method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.00      0.00      0.00      1169\n",
      "        True       0.54      1.00      0.70      1382\n",
      "\n",
      "   micro avg       0.54      0.54      0.54      2551\n",
      "   macro avg       0.27      0.50      0.35      2551\n",
      "weighted avg       0.29      0.54      0.38      2551\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harikesh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Harikesh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Harikesh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "random_forest_final = Pipeline([\n",
    "       ('rf_tfidf',TfidfVectorizer(stop_words='english',ngram_range=(1,3),use_idf=True,smooth_idf=True)),\n",
    "       ('rf_clf',RandomForestClassifier(n_estimators=300,n_jobs=3,max_depth=10))\n",
    "       ])\n",
    "   \n",
    "random_forest_final.fit(DataPrep.train_news['Statement'],DataPrep.train_news['Label'])\n",
    "predicted_rf_final = random_forest_final.predict(DataPrep.test_news['Statement'])\n",
    "np.mean(predicted_rf_final == DataPrep.test_news['Label'])\n",
    "print(classification_report(DataPrep.test_news['Label'], predicted_rf_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harikesh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.64      0.38      0.48      1169\n",
      "        True       0.61      0.82      0.70      1382\n",
      "\n",
      "   micro avg       0.62      0.62      0.62      2551\n",
      "   macro avg       0.62      0.60      0.59      2551\n",
      "weighted avg       0.62      0.62      0.60      2551\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logR_pipeline_final = Pipeline([\n",
    "        #('LogRCV',countV_ngram),\n",
    "        ('LogR_tfidf',TfidfVectorizer(stop_words='english',ngram_range=(1,5),use_idf=True,smooth_idf=False)),\n",
    "        ('LogR_clf',LogisticRegression(penalty=\"l2\",C=1))\n",
    "        ])\n",
    "\n",
    "logR_pipeline_final.fit(DataPrep.train_news['Statement'],DataPrep.train_news['Label'])\n",
    "predicted_LogR_final = logR_pipeline_final.predict(DataPrep.test_news['Statement'])\n",
    "np.mean(predicted_LogR_final == DataPrep.test_news['Label'])\n",
    "#accuracy = 0.62\n",
    "print(classification_report(DataPrep.test_news['Label'], predicted_LogR_final))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving best model to the disk\n",
    "model_file = 'final_model.sav'\n",
    "pickle.dump(logR_pipeline_ngram,open(model_file,'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(pipeline,title):\n",
    "    size = 10000\n",
    "    cv = KFold(size, shuffle=True)\n",
    "    \n",
    "    X = DataPrep.train_news[\"Statement\"]\n",
    "    y = DataPrep.train_news[\"Label\"]\n",
    "    \n",
    "    pl = pipeline\n",
    "    pl.fit(X,y)\n",
    "    \n",
    "    train_sizes, train_scores, test_scores = learning_curve(pl, X, y, n_jobs=-1, cv=cv, train_sizes=np.linspace(.1, 1.0, 5), verbose=0)\n",
    "       \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "     \n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    \n",
    "    # box-like grid\n",
    "    plt.grid()\n",
    "    \n",
    "    # plot the std deviation as a transparent range at each training set size\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    \n",
    "    # plot the average training and test score lines at each training set size\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "    \n",
    "    # sizes the window for readability and displays the plot\n",
    "    # shows error from 0 to 1.1\n",
    "    plt.ylim(-.1,1.1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_learning_curve(logR_pipeline_ngram,\"Naive-bayes Classifier\")\n",
    "# plot_learning_curve(nb_pipeline_ngram,\"LogisticRegression Classifier\")\n",
    "# plot_learning_curve(svm_pipeline_ngram,\"SVM Classifier\")\n",
    "#plot_learning_curve(sgd_pipeline_ngram,\"SGD Classifier\")\n",
    "#plot_learning_curve(random_forest_ngram,\"RandomForest Classifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting Precision-Recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_PR_curve(classifier):\n",
    "    \n",
    "    precision, recall, thresholds = precision_recall_curve(DataPrep.test_news['Label'], classifier)\n",
    "    average_precision = average_precision_score(DataPrep.test_news['Label'], classifier)\n",
    "    \n",
    "    plt.step(recall, precision, color='b', alpha=0.2,\n",
    "             where='post')\n",
    "    plt.fill_between(recall, precision, step='post', alpha=0.2,\n",
    "                     color='b')\n",
    "    \n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "#    plt.title('2-class Random Forest Precision-Recall curve: AP={0:0.2f}'.format(\n",
    "#              average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot_PR_curve(predicted_LogR_ngram)\n",
    "plot_PR_curve(predicted_rf_ngram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting the most informative features\n",
    "Now let's extract the most informative feature from TF-IDF vectorizer for all fo the classifiers and see of there are any common\n",
    "words that we can identify i.e. are these most informative feature acorss the classifiers are same? we will create a function that \n",
    "will extract top 50 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_most_informative_features(model, vect, clf, text=None, n=50):\n",
    "    # Extract the vectorizer and the classifier from the pipeline\n",
    "    vectorizer = model.named_steps[vect]\n",
    "    classifier = model.named_steps[clf]\n",
    "\n",
    "     # Check to make sure that we can perform this computation\n",
    "    if not hasattr(classifier, 'coef_'):\n",
    "        raise TypeError(\n",
    "            \"Cannot compute most informative features on {}.\".format(\n",
    "                classifier.__class__.__name__\n",
    "            )\n",
    "        )\n",
    "            \n",
    "    if text is not None:\n",
    "        # Compute the coefficients for the text\n",
    "        tvec = model.transform([text]).toarray()\n",
    "    else:\n",
    "        # Otherwise simply use the coefficients\n",
    "        tvec = classifier.coef_\n",
    "\n",
    "    # Zip the feature names with the coefs and sort\n",
    "    coefs = sorted(\n",
    "        zip(tvec[0], vectorizer.get_feature_names()),\n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    # Get the top n and bottom n coef, name pairs\n",
    "    topn  = zip(coefs[:n], coefs[:-(n+1):-1])\n",
    "\n",
    "    # Create the output string to return\n",
    "    output = []\n",
    "\n",
    "    # If text, add the predicted value to the output.\n",
    "    if text is not None:\n",
    "        output.append(\"\\\"{}\\\"\".format(text))\n",
    "        output.append(\n",
    "            \"Classified as: {}\".format(model.predict([text]))\n",
    "        )\n",
    "        output.append(\"\")\n",
    "\n",
    "    # Create two columns with most negative and most positive features.\n",
    "    for (cp, fnp), (cn, fnn) in topn:\n",
    "        output.append(\n",
    "            \"{:0.4f}{: >15}    {:0.4f}{: >15}\".format(\n",
    "                cp, fnp, cn, fnn\n",
    "            )\n",
    "        )\n",
    "    #return \"\\n\".join(output)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.1112        started    -0.0732      abortions', '0.0556took started begin president    -0.0732abortions demand', '0.0556took started begin    -0.0732         annies', '0.0556   took started    -0.0732    annies list', '0.0556           took    -0.0732annies list political', '0.0556started natural gas took    -0.0732annies list political group', '0.0556started natural gas    -0.0732         demand', '0.0556started natural    -0.0732          group', '0.0556started begin president george    -0.0732 group supports', '0.0556started begin president    -0.0732group supports trimester', '0.0556  started begin    -0.0732group supports trimester abortions', '0.0556start started natural gas    -0.0732           list', '0.0556start started natural    -0.0732 list political', '0.0556  start started    -0.0732list political group', '0.0556          start    -0.0732list political group supports', '0.0556president george bushs administration    -0.0732      political', '0.0556president george bushs    -0.0732political group', '0.0556president george    -0.0732political group supports', '0.0556      president    -0.0732political group supports trimester', '0.0556natural gas took started    -0.0732           says', '0.0556natural gas took    -0.0732    says annies', '0.0556    natural gas    -0.0732says annies list', '0.0556        natural    -0.0732says annies list political', '0.0556george bushs administration    -0.0732       supports', '0.0556   george bushs    -0.0732supports trimester', '0.0556         george    -0.0732supports trimester abortions', '0.0556gas took started begin    -0.0732supports trimester abortions demand', '0.0556gas took started    -0.0732      trimester', '0.0556       gas took    -0.0732trimester abortions', '0.0556            gas    -0.0732trimester abortions demand', '0.0556did decline coal start    0.0556 administration', '0.0556did decline coal    0.0556          begin', '0.0556    did decline    0.0556begin president', '0.0556            did    0.0556begin president george', '0.0556decline coal start started    0.0556begin president george bushs', '0.0556decline coal start    0.0556          bushs', '0.0556   decline coal    0.0556bushs administration', '0.0556        decline    0.0556           coal', '0.0556coal start started natural    0.0556     coal start', '0.0556coal start started    0.0556coal start started', '0.0556     coal start    0.0556coal start started natural', '0.0556           coal    0.0556        decline', '0.0556bushs administration    0.0556   decline coal', '0.0556          bushs    0.0556decline coal start', '0.0556begin president george bushs    0.0556decline coal start started', '0.0556begin president george    0.0556            did', '0.0556begin president    0.0556    did decline', '0.0556          begin    0.0556did decline coal', '0.0556 administration    0.0556did decline coal start', '-0.0732trimester abortions demand    0.0556            gas']\n",
      "['-4.2088        started    -4.4536      abortions', '-4.3237took started begin president    -4.4536abortions demand', '-4.3237took started begin    -4.4536         annies', '-4.3237   took started    -4.4536    annies list', '-4.3237           took    -4.4536annies list political', '-4.3237started natural gas took    -4.4536annies list political group', '-4.3237started natural gas    -4.4536         demand', '-4.3237started natural    -4.4536          group', '-4.3237started begin president george    -4.4536 group supports', '-4.3237started begin president    -4.4536group supports trimester', '-4.3237  started begin    -4.4536group supports trimester abortions', '-4.3237start started natural gas    -4.4536           list', '-4.3237start started natural    -4.4536 list political', '-4.3237  start started    -4.4536list political group', '-4.3237          start    -4.4536list political group supports', '-4.3237president george bushs administration    -4.4536      political', '-4.3237president george bushs    -4.4536political group', '-4.3237president george    -4.4536political group supports', '-4.3237      president    -4.4536political group supports trimester', '-4.3237natural gas took started    -4.4536           says', '-4.3237natural gas took    -4.4536    says annies', '-4.3237    natural gas    -4.4536says annies list', '-4.3237        natural    -4.4536says annies list political', '-4.3237george bushs administration    -4.4536       supports', '-4.3237   george bushs    -4.4536supports trimester', '-4.3237         george    -4.4536supports trimester abortions', '-4.3237gas took started begin    -4.4536supports trimester abortions demand', '-4.3237gas took started    -4.4536      trimester', '-4.3237       gas took    -4.4536trimester abortions', '-4.3237            gas    -4.4536trimester abortions demand', '-4.3237did decline coal start    -4.3237 administration', '-4.3237did decline coal    -4.3237          begin', '-4.3237    did decline    -4.3237begin president', '-4.3237            did    -4.3237begin president george', '-4.3237decline coal start started    -4.3237begin president george bushs', '-4.3237decline coal start    -4.3237          bushs', '-4.3237   decline coal    -4.3237bushs administration', '-4.3237        decline    -4.3237           coal', '-4.3237coal start started natural    -4.3237     coal start', '-4.3237coal start started    -4.3237coal start started', '-4.3237     coal start    -4.3237coal start started natural', '-4.3237           coal    -4.3237        decline', '-4.3237bushs administration    -4.3237   decline coal', '-4.3237          bushs    -4.3237decline coal start', '-4.3237begin president george bushs    -4.3237decline coal start started', '-4.3237begin president george    -4.3237            did', '-4.3237begin president    -4.3237    did decline', '-4.3237          begin    -4.3237did decline coal', '-4.3237 administration    -4.3237did decline coal start', '-4.4536trimester abortions demand    -4.3237            gas']\n",
      "['0.1849        started    -0.1217      abortions', '0.0924took started begin president    -0.1217abortions demand', '0.0924took started begin    -0.1217         annies', '0.0924   took started    -0.1217    annies list', '0.0924           took    -0.1217annies list political', '0.0924started natural gas took    -0.1217annies list political group', '0.0924started natural gas    -0.1217         demand', '0.0924started natural    -0.1217          group', '0.0924started begin president george    -0.1217 group supports', '0.0924started begin president    -0.1217group supports trimester', '0.0924  started begin    -0.1217group supports trimester abortions', '0.0924start started natural gas    -0.1217           list', '0.0924start started natural    -0.1217 list political', '0.0924  start started    -0.1217list political group', '0.0924          start    -0.1217list political group supports', '0.0924president george bushs administration    -0.1217      political', '0.0924president george bushs    -0.1217political group', '0.0924president george    -0.1217political group supports', '0.0924      president    -0.1217political group supports trimester', '0.0924natural gas took started    -0.1217           says', '0.0924natural gas took    -0.1217    says annies', '0.0924    natural gas    -0.1217says annies list', '0.0924        natural    -0.1217says annies list political', '0.0924george bushs administration    -0.1217       supports', '0.0924   george bushs    -0.1217supports trimester', '0.0924         george    -0.1217supports trimester abortions', '0.0924gas took started begin    -0.1217supports trimester abortions demand', '0.0924gas took started    -0.1217      trimester', '0.0924       gas took    -0.1217trimester abortions', '0.0924            gas    -0.1217trimester abortions demand', '0.0924did decline coal start    0.0924 administration', '0.0924did decline coal    0.0924          begin', '0.0924    did decline    0.0924begin president', '0.0924            did    0.0924begin president george', '0.0924decline coal start started    0.0924begin president george bushs', '0.0924decline coal start    0.0924          bushs', '0.0924   decline coal    0.0924bushs administration', '0.0924        decline    0.0924           coal', '0.0924coal start started natural    0.0924     coal start', '0.0924coal start started    0.0924coal start started', '0.0924     coal start    0.0924coal start started natural', '0.0924           coal    0.0924        decline', '0.0924bushs administration    0.0924   decline coal', '0.0924          bushs    0.0924decline coal start', '0.0924begin president george bushs    0.0924decline coal start started', '0.0924begin president george    0.0924            did', '0.0924begin president    0.0924    did decline', '0.0924          begin    0.0924did decline coal', '0.0924 administration    0.0924did decline coal start', '-0.1217trimester abortions demand    0.0924            gas']\n",
      "['1.4534        started    -0.9567      abortions', '0.7267took started begin president    -0.9567abortions demand', '0.7267took started begin    -0.9567         annies', '0.7267   took started    -0.9567    annies list', '0.7267           took    -0.9567annies list political', '0.7267started natural gas took    -0.9567annies list political group', '0.7267started natural gas    -0.9567         demand', '0.7267started natural    -0.9567          group', '0.7267started begin president george    -0.9567 group supports', '0.7267started begin president    -0.9567group supports trimester', '0.7267  started begin    -0.9567group supports trimester abortions', '0.7267start started natural gas    -0.9567           list', '0.7267start started natural    -0.9567 list political', '0.7267  start started    -0.9567list political group', '0.7267          start    -0.9567list political group supports', '0.7267president george bushs administration    -0.9567      political', '0.7267president george bushs    -0.9567political group', '0.7267president george    -0.9567political group supports', '0.7267      president    -0.9567political group supports trimester', '0.7267natural gas took started    -0.9567           says', '0.7267natural gas took    -0.9567    says annies', '0.7267    natural gas    -0.9567says annies list', '0.7267        natural    -0.9567says annies list political', '0.7267george bushs administration    -0.9567       supports', '0.7267   george bushs    -0.9567supports trimester', '0.7267         george    -0.9567supports trimester abortions', '0.7267gas took started begin    -0.9567supports trimester abortions demand', '0.7267gas took started    -0.9567      trimester', '0.7267       gas took    -0.9567trimester abortions', '0.7267            gas    -0.9567trimester abortions demand', '0.7267did decline coal start    0.7267 administration', '0.7267did decline coal    0.7267          begin', '0.7267    did decline    0.7267begin president', '0.7267            did    0.7267begin president george', '0.7267decline coal start started    0.7267begin president george bushs', '0.7267decline coal start    0.7267          bushs', '0.7267   decline coal    0.7267bushs administration', '0.7267        decline    0.7267           coal', '0.7267coal start started natural    0.7267     coal start', '0.7267coal start started    0.7267coal start started', '0.7267     coal start    0.7267coal start started natural', '0.7267           coal    0.7267        decline', '0.7267bushs administration    0.7267   decline coal', '0.7267          bushs    0.7267decline coal start', '0.7267begin president george bushs    0.7267decline coal start started', '0.7267begin president george    0.7267            did', '0.7267begin president    0.7267    did decline', '0.7267          begin    0.7267did decline coal', '0.7267 administration    0.7267did decline coal start', '-0.9567trimester abortions demand    0.7267            gas']\n"
     ]
    }
   ],
   "source": [
    "show_most_informative_features(logR_pipeline_ngram,vect='LogR_tfidf',clf='LogR_clf')\n",
    "show_most_informative_features(nb_pipeline_ngram,vect='nb_tfidf',clf='nb_clf')\n",
    "show_most_informative_features(svm_pipeline_ngram,vect='svm_tfidf',clf='svm_clf')\n",
    "show_most_informative_features(sgd_pipeline_ngram,vect='sgd_tfidf',clf='sgd_clf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
